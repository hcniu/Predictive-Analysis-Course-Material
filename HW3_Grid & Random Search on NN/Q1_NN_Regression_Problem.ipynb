{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(13)\n",
    "\n",
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import scikitplot as skplt\n",
    "from sklearn import neighbors, datasets, tree, linear_model, metrics,svm\n",
    "from sklearn.model_selection import cross_val_score, train_test_split,KFold\n",
    "import itertools\n",
    "from itertools import permutations\n",
    "from sklearn.metrics import recall_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('HW3.xlsx')\n",
    "df=df.drop(columns=['sequence_number','Purchase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Formating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=['US', 'source_a', 'source_c', 'source_b', 'source_d', 'source_e','source_m', 'source_o', 'source_h', 'source_r',\n",
    "   'source_s', 'source_t','source_u', 'source_p', 'source_x', 'source_w','Web order','Gender=male', 'Address_is_res']\n",
    "df[c] = df[c].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US                       object\n",
       "source_a                 object\n",
       "source_c                 object\n",
       "source_b                 object\n",
       "source_d                 object\n",
       "source_e                 object\n",
       "source_m                 object\n",
       "source_o                 object\n",
       "source_h                 object\n",
       "source_r                 object\n",
       "source_s                 object\n",
       "source_t                 object\n",
       "source_u                 object\n",
       "source_p                 object\n",
       "source_x                 object\n",
       "source_w                 object\n",
       "Freq                      int64\n",
       "last_update_days_ago      int64\n",
       "1st_update_days_ago       int64\n",
       "Web order                object\n",
       "Gender=male              object\n",
       "Address_is_res           object\n",
       "Spending                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Train and Test Data\n",
    "x_train,x_test,y_train,y_test = train_test_split(df.drop(columns=['Spending']),df['Spending'],test_size=0.2,random_state=9)\n",
    "\n",
    "#Standardization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "mms.fit(x_train[['Freq','last_update_days_ago','1st_update_days_ago']])\n",
    "x_train[['Freq','last_update_days_ago','1st_update_days_ago']]=mms.transform(x_train[['Freq','last_update_days_ago','1st_update_days_ago']])\n",
    "x_test[['Freq','last_update_days_ago','1st_update_days_ago']]=mms.transform(x_test[['Freq','last_update_days_ago','1st_update_days_ago']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With CV grid search, I found the best hyperparameter is alpha=1 and L1 ratio=0.7.\n",
      "MSE on Test Data: 31795.78\n"
     ]
    }
   ],
   "source": [
    "#Elastic Net Regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "grid={'alpha':[1,2,3,4,5,6,7,8,9,10],\n",
    "      'l1_ratio':[0.3,0.5,0.7]}\n",
    "EN_linear=ElasticNet(random_state=99)\n",
    "model = GridSearchCV(estimator=EN_linear, param_grid=grid, cv=5,scoring='neg_mean_squared_error')\n",
    "model.fit(x_train,y_train)\n",
    "print(\"With CV grid search, I found the best hyperparameter is alpha={} and L1 ratio={}.\".format(model.best_params_['alpha'],model.best_params_['l1_ratio']))\n",
    "print(\"MSE on Test Data: {}\".format(round((metrics.mean_squared_error(y_test, model.predict(x_test))),2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With CV grid search, I found the best hyperparameter is n_neighbors=5 and weights=distance.\n",
      "MSE on Test Data: 33890.18\n"
     ]
    }
   ],
   "source": [
    "#KNN regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "grid={'n_neighbors':[5,10,15,20,50,100,500],\n",
    "      'weights':['uniform','distance']}\n",
    "KNN=KNeighborsRegressor()\n",
    "model = GridSearchCV(estimator=KNN, param_grid=grid, cv=5,scoring='neg_mean_squared_error')\n",
    "model.fit(x_train,y_train)\n",
    "print(\"With CV grid search, I found the best hyperparameter is n_neighbors={} and weights={}.\".format(model.best_params_['n_neighbors'],model.best_params_['weights']))\n",
    "print(\"MSE on Test Data: {}\".format(round((metrics.mean_squared_error(y_test, model.predict(x_test))),2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With CV grid search, I found the best hyperparameter is max_depth=7 and min_sample_split=15.\n",
      "MSE on Test Data: 23458.39\n"
     ]
    }
   ],
   "source": [
    "#Regression Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "grid={'max_depth':[2,3,4,5,6,7,8,9,10,20],\n",
    "      'min_samples_split':[2,5,10,15,20]}\n",
    "Tree=DecisionTreeRegressor(random_state=99)\n",
    "model = GridSearchCV(estimator=Tree, param_grid=grid, cv=5,scoring='neg_mean_squared_error')\n",
    "model.fit(x_train,y_train)\n",
    "print(\"With CV grid search, I found the best hyperparameter is max_depth={} and min_sample_split={}.\".format(model.best_params_['max_depth'],model.best_params_['min_samples_split']))\n",
    "print(\"MSE on Test Data: {}\".format(round((metrics.mean_squared_error(y_test, model.predict(x_test))),2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With CV grid search, I found the best hyperparameter is kernel=linear and C=10.\n",
      "MSE on Test Data: 27265.73\n"
     ]
    }
   ],
   "source": [
    "#SVM Regression\n",
    "from sklearn.svm import SVR\n",
    "grid={'kernel':['linear','rbf'],\n",
    "      'C':[1,2,3,4,5,6,7,8,9,10]}\n",
    "s=SVR()\n",
    "model = GridSearchCV(estimator=s, param_grid=grid, cv=5,scoring='neg_mean_squared_error')\n",
    "model.fit(x_train,y_train)\n",
    "print(\"With CV grid search, I found the best hyperparameter is kernel={} and C={}.\".format(model.best_params_['kernel'],model.best_params_['C']))\n",
    "print(\"MSE on Test Data: {}\".format(round((metrics.mean_squared_error(y_test, model.predict(x_test))),2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kerastuner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/haochunniu/Desktop/Python/Predictive Analysis/HW3_Grid & Random Search on NN/Q1_NN_Regression_Problem.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/haochunniu/Desktop/Python/Predictive%20Analysis/HW3_Grid%20%26%20Random%20Search%20on%20NN/Q1_NN_Regression_Problem.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/haochunniu/Desktop/Python/Predictive%20Analysis/HW3_Grid%20%26%20Random%20Search%20on%20NN/Q1_NN_Regression_Problem.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/haochunniu/Desktop/Python/Predictive%20Analysis/HW3_Grid%20%26%20Random%20Search%20on%20NN/Q1_NN_Regression_Problem.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkerastuner\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtuners\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomSearch\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kerastuner'"
     ]
    }
   ],
   "source": [
    "# Random Search With Neural Network\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 40s]\n",
      "mse: 18517.412109375\n",
      "\n",
      "Best mse So Far: 5621.048177083333\n",
      "Total elapsed time: 00h 01m 58s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=hp.Int('units',\n",
    "                                        min_value=10,\n",
    "                                        max_value=100,\n",
    "                                        step=10),\n",
    "                           activation='relu',input_dim=22))\n",
    "    model.add(layers.Dense(units=hp.Int('units',\n",
    "                                        min_value=10,\n",
    "                                        max_value=100,\n",
    "                                        step=10),\n",
    "                           activation='relu'))\n",
    "    model.add(layers.Dense(1,activation='linear'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',\n",
    "                                                            values=[0.01,0.001,0.0001])),\n",
    "                 loss='mse',\n",
    "                 metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "tuner=RandomSearch(build_model,\n",
    "                   objective='mse',\n",
    "                   max_trials=3,\n",
    "                   overwrite=True, #Always remember this\n",
    "                   executions_per_trial=3)\n",
    "\n",
    "#Keras cannot input object data type, so no matter the column is boolean or numeric we need to transform them to float32\n",
    "x_train_float = np.asarray(x_train).astype(np.float32)\n",
    "y_train_float = np.asarray(y_train).astype(np.float32)\n",
    "x_test_float = np.asarray(x_test).astype(np.float32)\n",
    "y_test_float = np.asarray(y_test).astype(np.float32)\n",
    "\n",
    "tuner.search(x=x_train_float,y=y_train_float,epochs=200,batch_size=32,validation_data=(x_test_float,y_test_float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best 3 layers NN parameters would be 80 neurons and 0.01 learning rate.\n",
      "------------------------------------------\n",
      "The best model's mse on test data = 5621\n",
      "------------------------------------------\n",
      "Results summary\n",
      "Results in ./untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='mse', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 80\n",
      "learning_rate: 0.01\n",
      "Score: 5621.048177083333\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 70\n",
      "learning_rate: 0.0001\n",
      "Score: 18517.412109375\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 60\n",
      "learning_rate: 0.0001\n",
      "Score: 20536.832682291668\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "result=tuner.get_best_hyperparameters()[0].values\n",
    "print('The best 3 layers NN parameters would be {} neurons and {} learning rate.'.format(result['units'],result['learning_rate']))\n",
    "print('------------------------------------------')\n",
    "print(\"The best model's mse on test data = 5621\")\n",
    "print('------------------------------------------')\n",
    "print(tuner.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With CV grid search, I found the best hyperparameter is n_estimators=100 and max_depth=8.\n",
      "MSE on Test Data: 23006.77\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "grid={'n_estimators':[100,200,300,400,500],\n",
    "      'max_depth':[1,2,3,4,5,6,7,8,9,10]}\n",
    "rf=RandomForestRegressor()\n",
    "model = GridSearchCV(estimator=rf, param_grid=grid, cv=5,scoring='neg_mean_squared_error')\n",
    "model.fit(x_train,y_train)\n",
    "print(\"With CV grid search, I found the best hyperparameter is n_estimators={} and max_depth={}.\".format(model.best_params_['n_estimators'],model.best_params_['max_depth']))\n",
    "print(\"MSE on Test Data: {}\".format(round((metrics.mean_squared_error(y_test, model.predict(x_test))),2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:  \n",
    "The **3 layers Neural Network with 80 Neurons** in each layer and **learning rate = 0.01** has the best predictive ability. **The MSE on test data is around 5484**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('HW3.xlsx')\n",
    "\n",
    "#Include only the purchase data\n",
    "df=df[df['Purchase']==1]\n",
    "df=df.drop(columns=['sequence_number','Purchase'])\n",
    "\n",
    "#Formating\n",
    "c=['US', 'source_a', 'source_c', 'source_b', 'source_d', 'source_e','source_m', 'source_o', 'source_h', 'source_r',\n",
    "   'source_s', 'source_t','source_u', 'source_p', 'source_x', 'source_w','Web order','Gender=male', 'Address_is_res']\n",
    "df[c] = df[c].astype(str)\n",
    "\n",
    "#Split Train and Test Data\n",
    "x_train,x_test,y_train,y_test = train_test_split(df.drop(columns=['Spending']),df['Spending'],test_size=0.2,random_state=9)\n",
    "\n",
    "#Standardization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "mms.fit(x_train[['Freq','last_update_days_ago','1st_update_days_ago']])\n",
    "x_train[['Freq','last_update_days_ago','1st_update_days_ago']]=mms.transform(x_train[['Freq','last_update_days_ago','1st_update_days_ago']])\n",
    "x_test[['Freq','last_update_days_ago','1st_update_days_ago']]=mms.transform(x_test[['Freq','last_update_days_ago','1st_update_days_ago']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With CV grid search, I found the best hyperparameter is alpha=1 and L1 ratio=0.7.\n",
      "MSE on Test Data: 58009.48\n"
     ]
    }
   ],
   "source": [
    "#Elastic Net Regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "grid={'alpha':[1,2,3,4,5,6,7,8,9,10],\n",
    "      'l1_ratio':[0.3,0.5,0.7]}\n",
    "EN_linear=ElasticNet(random_state=99)\n",
    "model = GridSearchCV(estimator=EN_linear, param_grid=grid, cv=5,scoring='neg_mean_squared_error')\n",
    "model.fit(x_train,y_train)\n",
    "print(\"With CV grid search, I found the best hyperparameter is alpha={} and L1 ratio={}.\".format(model.best_params_['alpha'],model.best_params_['l1_ratio']))\n",
    "print(\"MSE on Test Data: {}\".format(round((metrics.mean_squared_error(y_test, model.predict(x_test))),2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With CV grid search, I found the best hyperparameter is n_neighbors=5 and weights=distance.\n",
      "MSE on Test Data: 62928.14\n"
     ]
    }
   ],
   "source": [
    "#KNN regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "grid={'n_neighbors':[5,10,15,20,50,100,500],\n",
    "      'weights':['uniform','distance']}\n",
    "KNN=KNeighborsRegressor()\n",
    "model = GridSearchCV(estimator=KNN, param_grid=grid, cv=5,scoring='neg_mean_squared_error')\n",
    "model.fit(x_train,y_train)\n",
    "print(\"With CV grid search, I found the best hyperparameter is n_neighbors={} and weights={}.\".format(model.best_params_['n_neighbors'],model.best_params_['weights']))\n",
    "print(\"MSE on Test Data: {}\".format(round((metrics.mean_squared_error(y_test, model.predict(x_test))),2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With CV grid search, I found the best hyperparameter is max_depth=3 and min_sample_split=2.\n",
      "MSE on Test Data: 38713.35\n"
     ]
    }
   ],
   "source": [
    "#Regression Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "grid={'max_depth':[2,3,4,5,6,7,8,9,10,20],\n",
    "      'min_samples_split':[2,5,10,15,20]}\n",
    "Tree=DecisionTreeRegressor(random_state=99)\n",
    "model = GridSearchCV(estimator=Tree, param_grid=grid, cv=5,scoring='neg_mean_squared_error')\n",
    "model.fit(x_train,y_train)\n",
    "print(\"With CV grid search, I found the best hyperparameter is max_depth={} and min_sample_split={}.\".format(model.best_params_['max_depth'],model.best_params_['min_samples_split']))\n",
    "print(\"MSE on Test Data: {}\".format(round((metrics.mean_squared_error(y_test, model.predict(x_test))),2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With CV grid search, I found the best hyperparameter is kernel=linear and C=10.\n",
      "MSE on Test Data: 51984.36\n"
     ]
    }
   ],
   "source": [
    "#SVM Regression\n",
    "from sklearn.svm import SVR\n",
    "grid={'kernel':['linear','rbf'],\n",
    "      'C':[1,2,3,4,5,6,7,8,9,10]}\n",
    "s=SVR()\n",
    "model = GridSearchCV(estimator=s, param_grid=grid, cv=5,scoring='neg_mean_squared_error')\n",
    "model.fit(x_train,y_train)\n",
    "print(\"With CV grid search, I found the best hyperparameter is kernel={} and C={}.\".format(model.best_params_['kernel'],model.best_params_['C']))\n",
    "print(\"MSE on Test Data: {}\".format(round((metrics.mean_squared_error(y_test, model.predict(x_test))),2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search With Neural Network\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 27s]\n",
      "mse: 37634.412760416664\n",
      "\n",
      "Best mse So Far: 9512.133463541666\n",
      "Total elapsed time: 00h 01m 20s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=hp.Int('units',\n",
    "                                        min_value=10,\n",
    "                                        max_value=100,\n",
    "                                        step=10),\n",
    "                           activation='relu',input_dim=22))\n",
    "    model.add(layers.Dense(units=hp.Int('units',\n",
    "                                        min_value=10,\n",
    "                                        max_value=100,\n",
    "                                        step=10),\n",
    "                           activation='relu'))\n",
    "    model.add(layers.Dense(1,activation='linear'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',\n",
    "                                                            values=[0.01,0.001,0.0001])),\n",
    "                 loss='mse',\n",
    "                 metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "tuner=RandomSearch(build_model,\n",
    "                   objective='mse',\n",
    "                   max_trials=3,\n",
    "                   overwrite=True,\n",
    "                   executions_per_trial=3)\n",
    "\n",
    "#Keras cannot input object data type, so no matter the column is boolean or numeric we need to transform them to float32\n",
    "x_train_float = np.asarray(x_train).astype(np.float32)\n",
    "y_train_float = np.asarray(y_train).astype(np.float32)\n",
    "x_test_float = np.asarray(x_test).astype(np.float32)\n",
    "y_test_float = np.asarray(y_test).astype(np.float32)\n",
    "\n",
    "tuner.search(x=x_train_float,y=y_train_float,epochs=200,batch_size=32,validation_data=(x_test_float,y_test_float))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best 3 layers NN parameters would be 80 neurons and 0.01 learning rate.\n",
      "------------------------------------------\n",
      "The best model's mse on test data = 9512\n",
      "------------------------------------------\n",
      "Results summary\n",
      "Results in ./untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='mse', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 80\n",
      "learning_rate: 0.01\n",
      "Score: 9512.133463541666\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 60\n",
      "learning_rate: 0.001\n",
      "Score: 19139.3359375\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 90\n",
      "learning_rate: 0.0001\n",
      "Score: 37634.412760416664\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "result=tuner.get_best_hyperparameters()[0].values\n",
    "print('The best 3 layers NN parameters would be {} neurons and {} learning rate.'.format(result['units'],result['learning_rate']))\n",
    "print('------------------------------------------')\n",
    "print(\"The best model's mse on test data = 9512\")\n",
    "print('------------------------------------------')\n",
    "print(tuner.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With CV grid search, I found the best hyperparameter is n_estimators=400 and max_depth=4.\n",
      "MSE on Test Data: 39281.85\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "grid={'n_estimators':[100,200,300,400,500],\n",
    "      'max_depth':[1,2,3,4,5,6,7,8,9,10]}\n",
    "rf=RandomForestRegressor()\n",
    "model = GridSearchCV(estimator=rf, param_grid=grid, cv=5,scoring='neg_mean_squared_error')\n",
    "model.fit(x_train,y_train)\n",
    "print(\"With CV grid search, I found the best hyperparameter is n_estimators={} and max_depth={}.\".format(model.best_params_['n_estimators'],model.best_params_['max_depth']))\n",
    "print(\"MSE on Test Data: {}\".format(round((metrics.mean_squared_error(y_test, model.predict(x_test))),2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For full data, including **both purchased and non-purchased data**, **tree based models (Regression Tree, Ramdom Forest Regression) and Neural Network have the better performances**. On the other hand, for **purchased data only**, **tree based models (Regression Tree, Random Forest Regression) and Neural Network also have the better performances**. In general, **after the purchased data is excluded, all models' performances droppped dramatically**. I believe the reason is **because those who do not purchase and spend 0 dollars have very similar traits. On the other hand, those who do purchase and spend more than 0 dollar have very diverse traits**. Therefore, out models' performances drop dramatically."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
